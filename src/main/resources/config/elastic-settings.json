{
    "index": {
        "analysis": {
            "analyzer": {
                "my_ngram_analyzer": {
                    "tokenizer": "my_ngram_tokenizer",
                    "filter": [
                        "standard",
                        "asciifolding",
                        "lowercase",
                        "english_stop",
                        "english_stemmer",
                        "english_possessive_stemmer"
                    ]
                }
            },
            "filter" : {
                "english_stop": {
                    "type":       "stop",
                    "stopwords":  "_english_"
                },
                "english_stemmer": {
                    "type":       "stemmer",
                    "language":   "english"
                },
                "english_possessive_stemmer": {
                    "type":       "stemmer",
                    "language":   "possessive_english"
                }
            },
            "tokenizer": {
                "my_ngram_tokenizer": {
                    "type": "nGram",
                    "min_gram": "2",
                    "max_gram": "20",
                    "token_chars": [
                        "letter",
                        "digit"
                    ]
                }
            }
        }
    }
}
